{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Tf-IDF\n",
    "\n",
    "In this notebook you will be exploring the computation of the Tf-IDF feature using a very popular dataset called 20 newsgroups.\n",
    "\n",
    "The resources you should use to complete this notebook are:\n",
    "1.  https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "2.  http://www.tfidf.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 20 newsgroups by date dataset\n",
      "Number of posts 11314\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAERCAYAAACO6FuTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f40b5e05250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First post!\n",
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from math import log\n",
    "import seaborn as sns\n",
    "\n",
    "data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "post_texts = data.data\n",
    "news_group_ids = data.target\n",
    "\n",
    "print data.description\n",
    "\n",
    "print \"Number of posts\", len(data.data)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(data.target, bins=20)\n",
    "plt.xlabel('Newsgroup Id')\n",
    "plt.ylabel('Number of Posts')\n",
    "plt.show()\n",
    "\n",
    "print \"First post!\"\n",
    "print data.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readable(text):\n",
    "    replace = [',', '.', '\\n', '/', '!', '?']\n",
    "    \n",
    "    for char in replace:\n",
    "        text = text.replace(char, ' ')\n",
    "        \n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will be writing a function to compute the term frequency part of [Tf-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf).  It's up to you how fancy to make this function.  In my simple version, I used split after first removing leading or trailing punctuation (I used the `strip` function) and also converting the words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency count:  6\n",
      "Normalized count:  0.0659340659341\n",
      "Augmented count:  1.0\n",
      "Log-scale count:  2.79175946923\n"
     ]
    }
   ],
   "source": [
    "def tf(text, method='freq'):\n",
    "    \"\"\" Returns a dictionary where keys are words that occur in text\n",
    "        and the value is based on the (method):\n",
    "        \n",
    "        freq: word count in text\n",
    "        norm: ratio of word count to total words in text\n",
    "        aug: ratio of word count to max word count in text\n",
    "        log: logarithmically scaled word count in text       \n",
    "        \"\"\"\n",
    "    \n",
    "    word_freq = {}\n",
    "\n",
    "    words = readable(text)\n",
    "    \n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word in word_freq:\n",
    "            word_freq[word] += 1\n",
    "        else:\n",
    "            word_freq[word] = 1\n",
    "    \n",
    "    if method == 'freq': pass\n",
    "    \n",
    "    elif method == 'norm':\n",
    "        for word, freq in word_freq.iteritems():\n",
    "            word_freq[word] = freq/float(len(words))\n",
    "            \n",
    "    elif method == 'aug':\n",
    "        max_freq = max(word_freq.values())\n",
    "        for word, freq in word_freq.iteritems():\n",
    "            word_freq[word] = freq/float(max_freq)\n",
    "            \n",
    "    elif method == 'log':\n",
    "        for word, freq in word_freq.iteritems():\n",
    "            word_freq[word] = 1 + math.log(freq)\n",
    "    \n",
    "    return word_freq\n",
    "    \n",
    "\n",
    "print 'Frequency count: ', tf(data.data[0])['the']\n",
    "print 'Normalized count: ', tf(data.data[0], 'norm')['the']\n",
    "print 'Augmented count: ', tf(data.data[0], 'aug')['the']\n",
    "print 'Log-scale count: ', tf(data.data[0], 'log')['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will be writing a function to compute the inverse document frequency part of [Tf-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.306177440742 0.179285688888 0.474858953937\n",
      "Lowest IDF (most common)\n",
      "(u'the', 0.17928568888758886)\n",
      "(u'to', 0.29566862657258514)\n",
      "(u'a', 0.3061774407422126)\n",
      "(u'and', 0.38339301607014037)\n",
      "(u'of', 0.3904206347899775)\n",
      "(u'i', 0.45348881691922943)\n",
      "(u'in', 0.47485895393655214)\n",
      "(u'is', 0.48256227305706567)\n",
      "(u'that', 0.562891431606236)\n",
      "(u'it', 0.5888301647889916)\n",
      "\n",
      "Highest IDF (least common)\n",
      "(u'jawbone', 9.333796175903101)\n",
      "(u'false-alarms', 9.333796175903101)\n",
      "(u'm5y$*uv+)m:$hc:@])yh#m8*34cep:u-i\"ebfgi', 9.333796175903101)\n",
      "(u'92-cover', 9.333796175903101)\n",
      "(u'\"push-in\"', 9.333796175903101)\n",
      "(u\"\\\\qev#p'g\\\\'wqq\", 9.333796175903101)\n",
      "(u'x(1)', 9.333796175903101)\n",
      "(u'codings', 9.333796175903101)\n",
      "(u'bigotry)', 9.333796175903101)\n",
      "(u'(s)wine', 9.333796175903101)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import operator\n",
    "\n",
    "def idf(data):\n",
    "    \"\"\" Returns a dictionary where the keys are words and the values are inverse\n",
    "        document frequencies.  For this function you should use the formula\n",
    "        idf(w, data) = log(N / |text in data that contain the word w|) \"\"\"\n",
    "\n",
    "    word_pres = {}\n",
    "    num_posts = len(data)\n",
    "    \n",
    "    for post in data:\n",
    "        in_post = []\n",
    "        words = readable(post)\n",
    "\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            \n",
    "            #If the word has already been found in this post, don't consider it\n",
    "            if word in in_post: continue\n",
    "            in_post.append(word)\n",
    "        \n",
    "            if word in word_pres:\n",
    "                word_pres[word] += 1\n",
    "            else:\n",
    "                word_pres[word] = 1\n",
    "\n",
    "    #Replace simple frequency with inverse doc freq\n",
    "    for word, freq in word_pres.iteritems():\n",
    "        word_pres[word] = log(num_posts / float(freq))\n",
    "    \n",
    "    return word_pres\n",
    "\n",
    "idf = idf(data.data)\n",
    "sorted_idf = sorted(idf.items(), key=operator.itemgetter(1))\n",
    "\n",
    "print \"Lowest IDF (most common)\"\n",
    "for d in sorted_idf[0:10]:\n",
    "    print d\n",
    "\n",
    "print \"\"\n",
    "print \"Highest IDF (least common)\"\n",
    "rev_sorted_idf = sorted(idf.items(), key=operator.itemgetter(1))\n",
    "for d in reversed(rev_sorted_idf[-10:]):\n",
    "    print d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step in Tf-IDF is to compute the product of tf and IDF for each document, and then convert the resultant dictionary of Tf-IDF features into a vector.  We'll be discussing this next class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clarifying Questions\n",
    "\n",
    "Use this space to ask questions regarding the content covered in the reading. These questions should be restricted to helping you better understand the material. For questions that push beyond what is in the reading, use the next answer field. If you don't have a fully formed question, but are generally having a difficult time with a topic, you can indicate that here as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrichment Questions\n",
    "\n",
    "Use this space to ask any questions that go beyond (but are related to) the material presented in this reading. Perhaps there is a particular topic you'd like to see covered in more depth. Perhaps you'd like to know how to use a library in a way that wasn't show in the reading. One way to think about this is what additional topics would you want covered in the next class (or addressed in a followup e-mail to the class). I'm a little fuzzy on what stuff will likely go here, so we'll see how things evolve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I found many different weighting formulas for both the tf and idf term, and I'd like to know when to use one over the other, and whether this depends on things like the type of text, the number of samples, etc. Also, are there correlated weighting schemes for tf and idf that need to be used together?**\n",
    "\n",
    "**And it looks like you can also have different weighting methods for the combined term!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources / Explorations\n",
    "\n",
    "If you found any useful resources, or tried some useful exercises that you'd like to report please do so here. Let us know what you did, what you learned, and how others can replicate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
